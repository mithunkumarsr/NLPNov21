{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "POSTagging.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mithunkumarsr/NLPNov21/blob/main/POSTagging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwnvqW698o7Z"
      },
      "source": [
        "# POS Tagging"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "0kDfSMTw8o7c"
      },
      "source": [
        "Goal of a POS tagger is to assign linguistic (mostly grammatical) information to sub-sentential units. Such units are called tokens and, most of the time, correspond to words and symbols (e.g. punctuation)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FJ5bOaS8-mq",
        "outputId": "2fe85063-4237-4e28-f108-87393357ba29"
      },
      "source": [
        "import nltk \n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6et8chH8o7d",
        "outputId": "04bddb0f-9b58-4bf3-9574-1cf30cb9e75e"
      },
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.tokenize import word_tokenize, sent_tokenize \n",
        "stop_words = set(stopwords.words('english')) \n",
        "  \n",
        "statement = \"Hello all, I am Dr. Mithun. \" \\\n",
        "            \"Welcome to the lab session of Natural Language Processing(NLP). \" \\\n",
        "            \"NLP is a very interesting area.\"\n",
        "\n",
        "# sent_tokenize is one of instances of  \n",
        "# PunktSentenceTokenizer from the nltk.tokenize.punkt module \n",
        "  \n",
        "tokenized = sent_tokenize(statement) \n",
        "for i in tokenized: \n",
        "      \n",
        "    # Word tokenizers is used to find the words  \n",
        "    # and punctuation in a string \n",
        "    wordsList = nltk.word_tokenize(i) \n",
        "  \n",
        "    # removing stop words from wordList \n",
        "    wordsList = [w for w in wordsList if not w in stop_words]  \n",
        "  \n",
        "    #  Using a Tagger. Which is part-of-speech  \n",
        "    # tagger or POS-tagger.  \n",
        "    tagged = nltk.pos_tag(wordsList) \n",
        "  \n",
        "    print(tagged) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[('Hello', 'NNP'), (',', ','), ('I', 'PRP'), ('Dr.', 'NNP'), ('Mithun', 'NNP'), ('.', '.')]\n",
            "[('Welcome', 'JJ'), ('lab', 'NN'), ('session', 'NN'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Processing', 'NNP'), ('(', '('), ('NLP', 'NNP'), (')', ')'), ('.', '.')]\n",
            "[('NLP', 'NNP'), ('interesting', 'JJ'), ('area', 'NN'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiwMZfbZ8o7f"
      },
      "source": [
        "# NLTK includes a diverse set of corpora which can be read using the nltk.corpus package. \n",
        "# Corpus : Body of text, singular. Corpora is the plural of this.\n",
        "# Most corpora consist of a set of files, each containing a document (or other pieces of text). \n",
        "# Each corpus reader provides a variety of methods to read data from the corpus, \n",
        "# depending on the format of the corpus. \n",
        "# NLTK's data package also contains a wide variety of annotated corpora. \n",
        "# For example, the Brown Corpus is annotated with part-of-speech tags\n",
        "# Indian Language POS-Tagged Corpus includes samples of Indian text annotated with part-of-speech tags"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8eKxMDT8o7g",
        "outputId": "165798f7-3d04-4cf8-c275-78c2358364a3"
      },
      "source": [
        "from nltk.corpus import brown\n",
        "nltk.download('brown')\n",
        "# Evaluate Unigram tag using brown corpus.\n",
        "brown_tagged_sents = brown.tagged_sents(categories='news')\n",
        "brown_sents = brown.sents(categories='news')\n",
        "# We train a UnigramTagger by specifying tagged sentence data as a parameter\n",
        "# when we initialize the tagger.\n",
        "unigram_tagger = nltk.UnigramTagger(brown_tagged_sents)\n",
        "print(unigram_tagger.tag(brown_sents[2008]))\n",
        "print(unigram_tagger.evaluate(brown_tagged_sents))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[('Others', 'NNS'), (',', ','), ('which', 'WDT'), ('are', 'BER'), ('reached', 'VBN'), ('by', 'IN'), ('walking', 'VBG'), ('up', 'RP'), ('a', 'AT'), ('single', 'AP'), ('flight', 'NN'), ('of', 'IN'), ('stairs', 'NNS'), (',', ','), ('have', 'HV'), ('balconies', 'NNS'), ('.', '.')]\n",
            "0.9349006503968017\n"
          ]
        }
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "m-uwL7Bs8o7g"
      },
      "source": [
        "# POS tagging is traditionally a supervised learning question, we need some sentences with POS tags to train and test with.\n",
        "In practice, people label a bunch of sentences then split them to make a test and train set. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3BTr_JX8o7h",
        "outputId": "c1348fb7-7758-42eb-f5c7-29e2bb836ebc"
      },
      "source": [
        "from nltk import UnigramTagger\n",
        "from nltk.corpus import brown\n",
        "nltk.download('universal_tagset')\n",
        "# Use the brown corpus with universal tagset for readability\n",
        "tagged_sentences = brown.tagged_sents(categories=\"news\", tagset=\"universal\")\n",
        "\n",
        "# 20% of the data for testing, and 80% for training\n",
        "i = int(len(tagged_sentences)*0.2)\n",
        "train_sentences = tagged_sentences[i:]\n",
        "test_sentences = tagged_sentences[:i]\n",
        "\n",
        "# Train the tagger with train sentences\n",
        "unigram_tagger = UnigramTagger(train_sentences)\n",
        "# Evaluate with test sentences\n",
        "# default evaluation metric for nltk taggers is accuracy\n",
        "accuracy = unigram_tagger.evaluate(test_sentences)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n",
            "Accuracy: 0.8630364649525858\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIIh1Hrd8o7i",
        "outputId": "6f524f51-0cec-4667-adc1-679e599409ee"
      },
      "source": [
        "# Other measures to evaluate the quality of POS tagging\n",
        "tagged_test_sentences = unigram_tagger.tag_sents([[token for token,tag in sent] for sent in test_sentences])\n",
        "gold = [str(tag) for sentence in test_sentences for token,tag in sentence]\n",
        "pred = [str(tag) for sentence in tagged_test_sentences for token,tag in sentence]\n",
        "from sklearn import metrics\n",
        "print(metrics.classification_report(gold, pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           .       1.00      1.00      1.00      2107\n",
            "         ADJ       0.89      0.79      0.84      1341\n",
            "         ADP       0.97      0.92      0.94      2621\n",
            "         ADV       0.93      0.79      0.86       573\n",
            "        CONJ       1.00      1.00      1.00       453\n",
            "         DET       1.00      0.99      1.00      2456\n",
            "        NOUN       0.96      0.76      0.85      6265\n",
            "         NUM       0.99      0.85      0.92       379\n",
            "        None       0.00      0.00      0.00         0\n",
            "        PRON       1.00      0.96      0.98       502\n",
            "         PRT       0.69      0.96      0.80       481\n",
            "        VERB       0.96      0.83      0.89      3274\n",
            "           X       0.10      0.17      0.12         6\n",
            "\n",
            "    accuracy                           0.86     20458\n",
            "   macro avg       0.81      0.77      0.78     20458\n",
            "weighted avg       0.96      0.86      0.91     20458\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}