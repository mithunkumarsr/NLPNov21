{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hidden Markov Model",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mithunkumarsr/NLPNov21/blob/main/Hidden_Markov_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rdBtoOZe05X"
      },
      "source": [
        "#**Hidden Markov Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30uAp9aikFl2"
      },
      "source": [
        "# pretty printing our  distributions\n",
        "import pandas as pd\n",
        "from tabulate import tabulate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74t7RmJlZuN8"
      },
      "source": [
        "def generate_sequence(states,sequence_length):    \n",
        "    all_sequences = []\n",
        "    nodes = []    \n",
        "    depth = sequence_length    \n",
        "    def gen_seq_recur(states,nodes,depth):\n",
        "        if depth == 0:\n",
        "            #print nodes\n",
        "            all_sequences.append(nodes)\n",
        "        else:\n",
        "            for state in states:\n",
        "                temp_nodes = list(nodes)\n",
        "                temp_nodes.append(state)\n",
        "                gen_seq_recur(states,temp_nodes,depth-1)\n",
        "    \n",
        "    gen_seq_recur(states,[],depth)\n",
        "                \n",
        "    return all_sequences\n",
        "\n",
        "def score_sequences(sequences,initial_probs,transition_probs,emission_probs,obs):\n",
        "    \n",
        "    best_score = -1\n",
        "    best_sequence = None\n",
        "    \n",
        "    sequence_scores = []\n",
        "    for seq in sequences:\n",
        "        total_score = 1\n",
        "        total_score_breakdown = []\n",
        "        first = True\n",
        "        for i in range(len(seq)):\n",
        "            state_score = 1\n",
        "            # compute transitition probability score\n",
        "            if first == True:\n",
        "                state_score *= initial_probs[seq[i]]\n",
        "                # reset first flag\n",
        "                first = False\n",
        "            else:  \n",
        "                state_score *= transition_probs[seq[i] + \"|\" + seq[i-1]]\n",
        "            # add to emission probability score\n",
        "            state_score *= emission_probs[obs[i] + \"|\" + seq[i]]\n",
        "            # update the total score\n",
        "            #print state_score\n",
        "            total_score *= state_score\n",
        "            total_score_breakdown.append(total_score)\n",
        "\n",
        "        if(total_score > best_score):\n",
        "            best_score = total_score\n",
        "            best_sequence = total_score_breakdown\n",
        "\n",
        "        sequence_scores.append(total_score)\n",
        "        \n",
        "    return best_sequence,sequence_scores\n",
        "\n",
        "def pretty_print_probs(distribs):\n",
        "    \n",
        "    rows = set()\n",
        "    cols = set()\n",
        "    for val in distribs.keys():\n",
        "        temp = val.split(\"|\")\n",
        "        rows.add(temp[0])\n",
        "        cols.add(temp[1])\n",
        "        \n",
        "    rows = list(rows)\n",
        "    cols = list(cols)\n",
        "    df = []\n",
        "    for i in range(len(rows)):\n",
        "        temp = []\n",
        "        for j in range(len(cols)):\n",
        "            temp.append(distribs[rows[i]+\"|\"+cols[j]])\n",
        "            \n",
        "        df.append(temp)\n",
        "        \n",
        "    I = pd.Index(rows, name=\"rows\")\n",
        "    C = pd.Index(cols, name=\"cols\")\n",
        "    df = pd.DataFrame(data=df,index=I, columns=C)\n",
        "    \n",
        "    print(tabulate(df, headers='keys', tablefmt='psql'))\n",
        "\n",
        "def initializeSequences(states,prob_dict,initial_probs,_obs):\n",
        "    # Generate list of sequences\n",
        "    transition_probs = prob_dict[0]\n",
        "    emission_probs = prob_dict[1]\n",
        "    seqLen = len(_obs)\n",
        "    seqs = generate_sequence(states,seqLen)\n",
        "    # Score sequences\n",
        "    best_seq,seq_scores = score_sequences(seqs,initial_probs,transition_probs,emission_probs,_obs)\n",
        "    \n",
        "    return (seqLen,seqs,best_seq,seq_scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHwnsz6-OLXo"
      },
      "source": [
        "#**Viterbi Algorithm**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmXiG9kaOQFq"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def viterbi(states,prob_dict,initial_probs,_obs):\n",
        "  '''\n",
        "  Parameters:\n",
        "  1. states - list of hidden states ['Hot','Cold','Mild']\n",
        "  2. prob_dict - tuple that contains the dictionaries transition_probs and emission probs\n",
        "     example of transition_probs:\n",
        "     transition_probs = {'Hot|Hot':0.6,'Hot|Mild':0.3,'Hot|Cold':0.1,\n",
        "                         'Mild|Hot':0.4,'Mild|Mild':0.3,'Mild|Cold':0.2,\n",
        "                         'Cold|Hot':0.1,'Cold|Mild':0.4,'Cold|Cold':0.5}\n",
        "\n",
        "     example of emission_probs:\n",
        "     emission_probs =   {'CasualWear|Hot':0.8,'CasualWear|Mild':0.19,'CasualWear|Cold':0.01,\n",
        "                         'SemiCasualWear|Hot':0.5,'SemiCasualWear|Mild':0.4,'SemiCasualWear|Cold':0.1,\n",
        "                         'ApparelWear|Hot':0.01,'ApparelWear|Mild':0.2,'ApparelWear|Cold':0.79}\n",
        "\n",
        "  3. _obs - list of a sequence of observable states\n",
        "     example of _obs = ['ApparelWear','CasualWear', 'CasualWear', 'SemiCasualWear']\n",
        "\n",
        "  Returns:\n",
        "  1. cache - required for backtracking to achieve the best hidden state sequence\n",
        "  2. viterbi_list - the index of the max value of this list is required to initiate backward pass of the Viterbi Algorithm\n",
        "  '''\n",
        "  # Generate list of sequences\n",
        "  n = len(states)\n",
        "  transition_probs = prob_dict[0]\n",
        "  emission_probs = prob_dict[1]\n",
        "  viterbi_list = []\n",
        "  cache = {}\n",
        "\n",
        "  for state in states:\n",
        "    viterbi_list.append(initial_probs[state]*emission_probs[_obs[0]+\"|\"+state])\n",
        "\n",
        "  for i,ob in enumerate(_obs):\n",
        "    if i==0: continue\n",
        "    temp_list = [None]*n\n",
        "    for j,state in enumerate(states):\n",
        "      x = -1\n",
        "      for k,prob in enumerate(viterbi_list):\n",
        "        val = prob*transition_probs[state+\"|\"+states[k]]*emission_probs[ob+\"|\"+state]\n",
        "        if (x<val):\n",
        "          x = val\n",
        "          cache[str(i)+\"-\"+state] = [states[k],val]\n",
        "      temp_list[j]= x\n",
        "    viterbi_list = [x for x in temp_list]\n",
        "    \n",
        "\n",
        "  return cache,viterbi_list\n",
        "\n",
        "def viterbi_backward(states,cache,viterbi_list):\n",
        "  '''\n",
        "  Parameters:\n",
        "\n",
        "  To be used by passing (states , return values of Viterbi Algorithm) as parameters\n",
        "\n",
        "  1. cache - dictionary that stores state information of algorithm\n",
        "     example of cache:\n",
        "     {'1-Hot': ['Cold', 0.015800000000000005], '1-Mild': ['Cold', 0.02528000000000001], '1-Cold': ['Cold', 0.015800000000000005], '2-Hot': ['Hot', 0.007584000000000002], '2-Mild': ['Mild', 0.0014409600000000007], '2-Cold': ['Mild', 0.00010112000000000005]}\n",
        "\n",
        "  2. viterbi_list - list of numeric values (one corresponding to each state)\n",
        "\n",
        "  Returns:\n",
        "  1. best_sequence - list of predicted hidden states \n",
        "     example of best_sequence:\n",
        "     best_sequence = ['Hot','Cold','Cold']...\n",
        "  \n",
        "  2. best_sequence_breakdown - list of probabilities at each stage (used for debugging)\n",
        "     example of best_sequence_breakdown:\n",
        "     best_sequence_breakdown = [0.5832000000000002, 0.4199040000000001, 0.3023308800000001]\n",
        "  '''\n",
        "  num_states = len(states)\n",
        "  n = len(cache)//num_states\n",
        "  best_sequence = []\n",
        "  best_sequence_breakdown=[]\n",
        "  x = states[np.argmax(np.asarray(viterbi_list))]\n",
        "  best_sequence.append(x)\n",
        "\n",
        "  for i in range(n,0,-1):\n",
        "    val = cache[str(i)+'-'+x][1]\n",
        "    x = cache[str(i)+'-'+x][0]\n",
        "    best_sequence = [x] + best_sequence\n",
        "    best_sequence_breakdown = [val]+best_sequence_breakdown\n",
        "  \n",
        "  return best_sequence,best_sequence_breakdown\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pkoetfFgt2R"
      },
      "source": [
        "#**Example 1** (Weather and dressing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIu8BcUtHr0p"
      },
      "source": [
        "Before actually start working on the dataset, let us understand the HMM using 2 examples.\n",
        "\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1Pkx_Smx3RNkIqtGJZvwBw8_Kz1D9U3oJ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yE1EKVNz6w7"
      },
      "source": [
        "**Hidden Markov Model** uses different probability theorems for finding a sequence of hidden states for a given observations (visible states). \n",
        "\n",
        "So let us assume, that we have lost the data of weather on 10th,11th and 12th of March 2019. Now we need to find the sequence of the weathers on that day (i.e. whether the sequence were *Hot->Hot->Cold* or *Mild->Cold->Hot* or *Cold->Cold->Hot* or some other sequence). \n",
        "\n",
        "Note that there are 27 such states (3^3).\n",
        "\n",
        "Now if you would have had the data then you would have known the sequence of the above *HIDDEN STATES* (hidden because they are unknown) but we have some other sequence (*SEQUENCE OF THE VISIBLE STATES*) with the help of which we can predict the sequence of the *HIDDEN STATES*. \n",
        "\n",
        "So you know that on 10th,11th and 12th of March of 2019, an XYZ person had worn a sequence of *Casual Wear->Casual Wear->Semi Casual Wear*. Now this sequence is your observation. Hence observations are generated over visible states. Therefore *'Casual Wear', 'WInter Apparel', 'Semi Casual Wear'* are visible states.\n",
        "\n",
        "We have \n",
        "1. Transition table: \n",
        "> That tells us, suppose today is a *Hot* day then what is the probability of tomorrow being a *Mild* day or *Cold* day or a *Hot* day again and so on. Hence `Transition[i][j] = P(today being [state i] | previous day is [state j])`\n",
        "\n",
        "2. Emission table:\n",
        "> This tells us the chance of it being *Hot* or *Cold* or *Mild* when XYZ wears a particular wear (*Casual* or *Winter* or *Semi Casual*). Hence `Emission[i][j] = P(wearing [i wear] | it is [j weather])`\n",
        "\n",
        "Using this information Hidden Markov Model can calculate the weather sequence with the highest chances. \n",
        "\n",
        "*To understand in **simple language**, if you are wearing a casual dress, a layman would guess that its a hot day and if you are wearing a woollen dress, a layman would guess that it may be a cold day. This is what HMM helps us in calculating. It observes a visible sequence to calculate the chances of a hidden sequence.*\n",
        "\n",
        "To understand the **MATH** behind it refer : https://web.stanford.edu/~jurafsky/slp3/A.pdf\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vFzuK_zZi6V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4b9f161a-5ba1-4fb8-b182-32d51583807d"
      },
      "source": [
        "def get_probs_ex1():\n",
        "  # transition probabilities\n",
        "  transition_probs = {'H|H':0.6,'H|M':0.3,'H|C':0.1,\n",
        "                      'M|H':0.4,'M|M':0.3,'M|C':0.2,\n",
        "                      'C|H':0.1,'C|M':0.4,'C|C':0.5}\n",
        "\n",
        "  # emission probabilities (CW-Casual Wear , SW-Semi Casual Wear , AW - Apparel)\n",
        "  emission_probs =   {'CW|H':0.8,'CW|M':0.19,'CW|C':0.01,\n",
        "                      'SW|H':0.5,'SW|M':0.4,'SW|C':0.1,\n",
        "                      'AW|H':0.01,'AW|M':0.2,'AW|C':0.79}\n",
        "                      \n",
        "  return transition_probs,emission_probs\n",
        "\n",
        "#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@\n",
        "\n",
        "# hidden states\n",
        "states1 = ['H','M','C']\n",
        "\n",
        "# set of observations\n",
        "obs = ['AW','SW','CW'] \n",
        "\n",
        "# initial state probability distribution (our priors)\n",
        "initial_probs1 = {'H':0.3,'M':0.3,'C':0.4}\n",
        "\n",
        "# Generate list of sequences\n",
        "sequence_length,sequences,best_sequence,sequence_scores = initializeSequences(states1,get_probs_ex1(),initial_probs1,obs)\n",
        "\n",
        "print(\"Initial Distributions\")\n",
        "print(initial_probs1)\n",
        "\n",
        "transition_probs, emission_probs = get_probs_ex1()\n",
        "\n",
        "print(\"\\nTransition Probabilities\")\n",
        "pretty_print_probs(transition_probs)\n",
        "\n",
        "print(\"\\nEmission Probabilities\")\n",
        "pretty_print_probs(emission_probs)\n",
        "\n",
        "print(\"\\nScores\")\n",
        "# Display sequence scores\n",
        "for i in range(len(sequences)):\n",
        "    print(\"Sequence:%10s,Score:%0.4f\" % (sequences[i],sequence_scores[i]))\n",
        "\n",
        "# The best sequence for the given observation (obs) and initial chances of the hidden states (initial_probs)\n",
        "best_seq_n = np.argmax(sequence_scores)\n",
        "print(\"\\nBest Sequence:\",sequences[best_seq_n],best_sequence)\n",
        "print()\n",
        "cache,l = viterbi(states1,get_probs_ex1(),initial_probs1,obs)\n",
        "\n",
        "print(\"Path generated by viterbi algorithm by reducing computation...\",cache,sep=\"\\n\")\n",
        "print()\n",
        "print(\"Finding the best hidden sequence from the path generated by viterbi algorithm...\")\n",
        "print(viterbi_backward(states1,cache,l),np.max(np.asarray(l)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial Distributions\n",
            "{'H': 0.3, 'M': 0.3, 'C': 0.4}\n",
            "\n",
            "Transition Probabilities\n",
            "+--------+-----+-----+-----+\n",
            "| rows   |   H |   C |   M |\n",
            "|--------+-----+-----+-----|\n",
            "| H      | 0.6 | 0.1 | 0.3 |\n",
            "| C      | 0.1 | 0.5 | 0.4 |\n",
            "| M      | 0.4 | 0.2 | 0.3 |\n",
            "+--------+-----+-----+-----+\n",
            "\n",
            "Emission Probabilities\n",
            "+--------+------+------+------+\n",
            "| rows   |    H |    C |    M |\n",
            "|--------+------+------+------|\n",
            "| CW     | 0.8  | 0.01 | 0.19 |\n",
            "| AW     | 0.01 | 0.79 | 0.2  |\n",
            "| SW     | 0.5  | 0.1  | 0.4  |\n",
            "+--------+------+------+------+\n",
            "\n",
            "Scores\n",
            "Sequence:['H', 'H', 'H'],Score:0.0004\n",
            "Sequence:['H', 'H', 'M'],Score:0.0001\n",
            "Sequence:['H', 'H', 'C'],Score:0.0000\n",
            "Sequence:['H', 'M', 'H'],Score:0.0001\n",
            "Sequence:['H', 'M', 'M'],Score:0.0000\n",
            "Sequence:['H', 'M', 'C'],Score:0.0000\n",
            "Sequence:['H', 'C', 'H'],Score:0.0000\n",
            "Sequence:['H', 'C', 'M'],Score:0.0000\n",
            "Sequence:['H', 'C', 'C'],Score:0.0000\n",
            "Sequence:['M', 'H', 'H'],Score:0.0043\n",
            "Sequence:['M', 'H', 'M'],Score:0.0007\n",
            "Sequence:['M', 'H', 'C'],Score:0.0000\n",
            "Sequence:['M', 'M', 'H'],Score:0.0017\n",
            "Sequence:['M', 'M', 'M'],Score:0.0004\n",
            "Sequence:['M', 'M', 'C'],Score:0.0000\n",
            "Sequence:['M', 'C', 'H'],Score:0.0002\n",
            "Sequence:['M', 'C', 'M'],Score:0.0001\n",
            "Sequence:['M', 'C', 'C'],Score:0.0000\n",
            "Sequence:['C', 'H', 'H'],Score:0.0076\n",
            "Sequence:['C', 'H', 'M'],Score:0.0012\n",
            "Sequence:['C', 'H', 'C'],Score:0.0000\n",
            "Sequence:['C', 'M', 'H'],Score:0.0061\n",
            "Sequence:['C', 'M', 'M'],Score:0.0014\n",
            "Sequence:['C', 'M', 'C'],Score:0.0001\n",
            "Sequence:['C', 'C', 'H'],Score:0.0013\n",
            "Sequence:['C', 'C', 'M'],Score:0.0006\n",
            "Sequence:['C', 'C', 'C'],Score:0.0001\n",
            "\n",
            "Best Sequence: ['C', 'H', 'H'] [0.31600000000000006, 0.015800000000000005, 0.007584000000000002]\n",
            "\n",
            "Path generated by viterbi algorithm by reducing computation...\n",
            "{'1-H': ['C', 0.015800000000000005], '1-M': ['C', 0.02528000000000001], '1-C': ['C', 0.015800000000000005], '2-H': ['H', 0.007584000000000002], '2-M': ['M', 0.0014409600000000007], '2-C': ['M', 0.00010112000000000005]}\n",
            "\n",
            "Finding the best hidden sequence from the path generated by viterbi algorithm...\n",
            "(['C', 'H', 'H'], [0.015800000000000005, 0.007584000000000002]) 0.007584000000000002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLzgAscgGO_8"
      },
      "source": [
        "In the above example, initial probabilities of it being a hot day, cold day or a mild day were equal. But since the observable sequence (`obs`) was `['CW','CW','CW']`, therefore our HMM predicted that the three days would have been `['H', 'H', 'H']`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyvT0IR7HORi"
      },
      "source": [
        "##**Example 2** (Simple Part of speech tagging)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkhvP8qhGM4V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "abf02851-ea3f-460f-d033-569d620afd10"
      },
      "source": [
        "def get_probs_ex2():\n",
        "  transition_probs = {'Noun|Noun':0.1,'Noun|Verb':0.1,'Noun|Determiner':0.8,\n",
        "                      'Verb|Noun':0.8,'Verb|Verb':0.1,'Verb|Determiner':0.1,\n",
        "                      'Determiner|Noun':0.1,'Determiner|Verb':0.8,'Determiner|Determiner':0.1}\n",
        "  emission_probs = {'Bob|Noun':0.9,'ate|Noun':0.05,'the|Noun':0.05,'fruit|Noun':0.9,\\\n",
        "                    'Bob|Verb':0.05,'ate|Verb':0.9,'the|Verb':0.05,'fruit|Verb':0.05,\\\n",
        "                    'Bob|Determiner':0.05,'ate|Determiner':0.05,'the|Determiner':0.9,'fruit|Determiner':0.05}\n",
        "  return transition_probs,emission_probs\n",
        "\n",
        "#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@\n",
        "\n",
        "# generate new sequences\n",
        "states2 = ['Noun','Verb','Determiner']\n",
        "\n",
        "initial_probs2 = {'Noun':0.9,'Verb':0.05,'Determiner':0.05}\n",
        "\n",
        "transition_probs, emission_probs = get_probs_ex2()\n",
        "\n",
        "print(\"Initial Distributions\")\n",
        "print(initial_probs2)\n",
        "print(\"\\nTransition Probabilities\")\n",
        "pretty_print_probs(transition_probs)\n",
        "print(\"\\nEmission Probabilities\")\n",
        "pretty_print_probs(emission_probs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial Distributions\n",
            "{'Noun': 0.9, 'Verb': 0.05, 'Determiner': 0.05}\n",
            "\n",
            "Transition Probabilities\n",
            "+------------+--------+--------+--------------+\n",
            "| rows       |   Verb |   Noun |   Determiner |\n",
            "|------------+--------+--------+--------------|\n",
            "| Verb       |    0.1 |    0.8 |          0.1 |\n",
            "| Noun       |    0.1 |    0.1 |          0.8 |\n",
            "| Determiner |    0.8 |    0.1 |          0.1 |\n",
            "+------------+--------+--------+--------------+\n",
            "\n",
            "Emission Probabilities\n",
            "+--------+--------+--------+--------------+\n",
            "| rows   |   Verb |   Noun |   Determiner |\n",
            "|--------+--------+--------+--------------|\n",
            "| ate    |   0.9  |   0.05 |         0.05 |\n",
            "| fruit  |   0.05 |   0.9  |         0.05 |\n",
            "| Bob    |   0.05 |   0.9  |         0.05 |\n",
            "| the    |   0.05 |   0.05 |         0.9  |\n",
            "+--------+--------+--------+--------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkM9Jp5dsdRu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dec42e19-4110-4609-9aaa-453453d8f189"
      },
      "source": [
        "obs = ['Bob','ate','the','fruit']\n",
        "\n",
        "# print results\n",
        "print(\"\\nScores\")\n",
        "\n",
        "# Generate list of sequences\n",
        "sequence_length,sequences,best_sequence,sequence_scores = initializeSequences(states2,get_probs_ex2(),initial_probs2,obs)\n",
        "\n",
        "# Display sequence scores\n",
        "# Total number of sequences are 3^4 = 81\n",
        "for i in range(len(sequences)):\n",
        "    print(\"Sequence:%-60s Score:%0.6f\" % (sequences[i],sequence_scores[i]))\n",
        "    \n",
        "# Display the winning score\n",
        "best_seq_n = np.argmax(sequence_scores)\n",
        "print(\"\\nBest Sequence:\",sequences[best_seq_n],best_sequence)\n",
        "print()\n",
        "cache,l = viterbi(states2,get_probs_ex2(),initial_probs2,obs)\n",
        "print(\"Path generated by viterbi algorithm by reducing computation...\",cache,sep=\"\\n\")\n",
        "print()\n",
        "print(\"Finding the best hidden sequence from the path generated by viterbi algorithm...\")\n",
        "print(viterbi_backward(states2,cache,l),np.max(np.asarray(l)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Scores\n",
            "Sequence:['Noun', 'Noun', 'Noun', 'Noun']                             Score:0.000002\n",
            "Sequence:['Noun', 'Noun', 'Noun', 'Verb']                             Score:0.000001\n",
            "Sequence:['Noun', 'Noun', 'Noun', 'Determiner']                       Score:0.000000\n",
            "Sequence:['Noun', 'Noun', 'Verb', 'Noun']                             Score:0.000015\n",
            "Sequence:['Noun', 'Noun', 'Verb', 'Verb']                             Score:0.000001\n",
            "Sequence:['Noun', 'Noun', 'Verb', 'Determiner']                       Score:0.000006\n",
            "Sequence:['Noun', 'Noun', 'Determiner', 'Noun']                       Score:0.000262\n",
            "Sequence:['Noun', 'Noun', 'Determiner', 'Verb']                       Score:0.000002\n",
            "Sequence:['Noun', 'Noun', 'Determiner', 'Determiner']                 Score:0.000002\n",
            "Sequence:['Noun', 'Verb', 'Noun', 'Noun']                             Score:0.000262\n",
            "Sequence:['Noun', 'Verb', 'Noun', 'Verb']                             Score:0.000117\n",
            "Sequence:['Noun', 'Verb', 'Noun', 'Determiner']                       Score:0.000015\n",
            "Sequence:['Noun', 'Verb', 'Verb', 'Noun']                             Score:0.000262\n",
            "Sequence:['Noun', 'Verb', 'Verb', 'Verb']                             Score:0.000015\n",
            "Sequence:['Noun', 'Verb', 'Verb', 'Determiner']                       Score:0.000117\n",
            "Sequence:['Noun', 'Verb', 'Determiner', 'Noun']                       Score:0.302331\n",
            "Sequence:['Noun', 'Verb', 'Determiner', 'Verb']                       Score:0.002100\n",
            "Sequence:['Noun', 'Verb', 'Determiner', 'Determiner']                 Score:0.002100\n",
            "Sequence:['Noun', 'Determiner', 'Noun', 'Noun']                       Score:0.000015\n",
            "Sequence:['Noun', 'Determiner', 'Noun', 'Verb']                       Score:0.000006\n",
            "Sequence:['Noun', 'Determiner', 'Noun', 'Determiner']                 Score:0.000001\n",
            "Sequence:['Noun', 'Determiner', 'Verb', 'Noun']                       Score:0.000002\n",
            "Sequence:['Noun', 'Determiner', 'Verb', 'Verb']                       Score:0.000000\n",
            "Sequence:['Noun', 'Determiner', 'Verb', 'Determiner']                 Score:0.000001\n",
            "Sequence:['Noun', 'Determiner', 'Determiner', 'Noun']                 Score:0.000262\n",
            "Sequence:['Noun', 'Determiner', 'Determiner', 'Verb']                 Score:0.000002\n",
            "Sequence:['Noun', 'Determiner', 'Determiner', 'Determiner']           Score:0.000002\n",
            "Sequence:['Verb', 'Noun', 'Noun', 'Noun']                             Score:0.000000\n",
            "Sequence:['Verb', 'Noun', 'Noun', 'Verb']                             Score:0.000000\n",
            "Sequence:['Verb', 'Noun', 'Noun', 'Determiner']                       Score:0.000000\n",
            "Sequence:['Verb', 'Noun', 'Verb', 'Noun']                             Score:0.000000\n",
            "Sequence:['Verb', 'Noun', 'Verb', 'Verb']                             Score:0.000000\n",
            "Sequence:['Verb', 'Noun', 'Verb', 'Determiner']                       Score:0.000000\n",
            "Sequence:['Verb', 'Noun', 'Determiner', 'Noun']                       Score:0.000001\n",
            "Sequence:['Verb', 'Noun', 'Determiner', 'Verb']                       Score:0.000000\n",
            "Sequence:['Verb', 'Noun', 'Determiner', 'Determiner']                 Score:0.000000\n",
            "Sequence:['Verb', 'Verb', 'Noun', 'Noun']                             Score:0.000000\n",
            "Sequence:['Verb', 'Verb', 'Noun', 'Verb']                             Score:0.000000\n",
            "Sequence:['Verb', 'Verb', 'Noun', 'Determiner']                       Score:0.000000\n",
            "Sequence:['Verb', 'Verb', 'Verb', 'Noun']                             Score:0.000000\n",
            "Sequence:['Verb', 'Verb', 'Verb', 'Verb']                             Score:0.000000\n",
            "Sequence:['Verb', 'Verb', 'Verb', 'Determiner']                       Score:0.000000\n",
            "Sequence:['Verb', 'Verb', 'Determiner', 'Noun']                       Score:0.000117\n",
            "Sequence:['Verb', 'Verb', 'Determiner', 'Verb']                       Score:0.000001\n",
            "Sequence:['Verb', 'Verb', 'Determiner', 'Determiner']                 Score:0.000001\n",
            "Sequence:['Verb', 'Determiner', 'Noun', 'Noun']                       Score:0.000000\n",
            "Sequence:['Verb', 'Determiner', 'Noun', 'Verb']                       Score:0.000000\n",
            "Sequence:['Verb', 'Determiner', 'Noun', 'Determiner']                 Score:0.000000\n",
            "Sequence:['Verb', 'Determiner', 'Verb', 'Noun']                       Score:0.000000\n",
            "Sequence:['Verb', 'Determiner', 'Verb', 'Verb']                       Score:0.000000\n",
            "Sequence:['Verb', 'Determiner', 'Verb', 'Determiner']                 Score:0.000000\n",
            "Sequence:['Verb', 'Determiner', 'Determiner', 'Noun']                 Score:0.000006\n",
            "Sequence:['Verb', 'Determiner', 'Determiner', 'Verb']                 Score:0.000000\n",
            "Sequence:['Verb', 'Determiner', 'Determiner', 'Determiner']           Score:0.000000\n",
            "Sequence:['Determiner', 'Noun', 'Noun', 'Noun']                       Score:0.000000\n",
            "Sequence:['Determiner', 'Noun', 'Noun', 'Verb']                       Score:0.000000\n",
            "Sequence:['Determiner', 'Noun', 'Noun', 'Determiner']                 Score:0.000000\n",
            "Sequence:['Determiner', 'Noun', 'Verb', 'Noun']                       Score:0.000000\n",
            "Sequence:['Determiner', 'Noun', 'Verb', 'Verb']                       Score:0.000000\n",
            "Sequence:['Determiner', 'Noun', 'Verb', 'Determiner']                 Score:0.000000\n",
            "Sequence:['Determiner', 'Noun', 'Determiner', 'Noun']                 Score:0.000006\n",
            "Sequence:['Determiner', 'Noun', 'Determiner', 'Verb']                 Score:0.000000\n",
            "Sequence:['Determiner', 'Noun', 'Determiner', 'Determiner']           Score:0.000000\n",
            "Sequence:['Determiner', 'Verb', 'Noun', 'Noun']                       Score:0.000000\n",
            "Sequence:['Determiner', 'Verb', 'Noun', 'Verb']                       Score:0.000000\n",
            "Sequence:['Determiner', 'Verb', 'Noun', 'Determiner']                 Score:0.000000\n",
            "Sequence:['Determiner', 'Verb', 'Verb', 'Noun']                       Score:0.000000\n",
            "Sequence:['Determiner', 'Verb', 'Verb', 'Verb']                       Score:0.000000\n",
            "Sequence:['Determiner', 'Verb', 'Verb', 'Determiner']                 Score:0.000000\n",
            "Sequence:['Determiner', 'Verb', 'Determiner', 'Noun']                 Score:0.000117\n",
            "Sequence:['Determiner', 'Verb', 'Determiner', 'Verb']                 Score:0.000001\n",
            "Sequence:['Determiner', 'Verb', 'Determiner', 'Determiner']           Score:0.000001\n",
            "Sequence:['Determiner', 'Determiner', 'Noun', 'Noun']                 Score:0.000000\n",
            "Sequence:['Determiner', 'Determiner', 'Noun', 'Verb']                 Score:0.000000\n",
            "Sequence:['Determiner', 'Determiner', 'Noun', 'Determiner']           Score:0.000000\n",
            "Sequence:['Determiner', 'Determiner', 'Verb', 'Noun']                 Score:0.000000\n",
            "Sequence:['Determiner', 'Determiner', 'Verb', 'Verb']                 Score:0.000000\n",
            "Sequence:['Determiner', 'Determiner', 'Verb', 'Determiner']           Score:0.000000\n",
            "Sequence:['Determiner', 'Determiner', 'Determiner', 'Noun']           Score:0.000001\n",
            "Sequence:['Determiner', 'Determiner', 'Determiner', 'Verb']           Score:0.000000\n",
            "Sequence:['Determiner', 'Determiner', 'Determiner', 'Determiner']     Score:0.000000\n",
            "\n",
            "Best Sequence: ['Noun', 'Verb', 'Determiner', 'Noun'] [0.81, 0.5832, 0.4199040000000001, 0.30233088000000014]\n",
            "\n",
            "Path generated by viterbi algorithm by reducing computation...\n",
            "{'1-Noun': ['Noun', 0.004050000000000001], '1-Verb': ['Noun', 0.5832000000000002], '1-Determiner': ['Noun', 0.004050000000000001], '2-Noun': ['Verb', 0.002916000000000001], '2-Verb': ['Verb', 0.002916000000000001], '2-Determiner': ['Verb', 0.4199040000000001], '3-Noun': ['Determiner', 0.3023308800000001], '3-Verb': ['Determiner', 0.0020995200000000006], '3-Determiner': ['Determiner', 0.0020995200000000006]}\n",
            "\n",
            "Finding the best hidden sequence from the path generated by viterbi algorithm...\n",
            "(['Noun', 'Verb', 'Determiner', 'Noun'], [0.5832000000000002, 0.4199040000000001, 0.3023308800000001]) 0.3023308800000001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-O2bo1MIM76E"
      },
      "source": [
        "We have correctly tagged the part of speech in \n",
        "\n",
        "\n",
        "\n",
        "1. Bob - Noun\n",
        "\n",
        "2. ate - Verb\n",
        "\n",
        "3. the - Determiner\n",
        "\n",
        "4. fruit - Noun\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZQPZVZUO8Um"
      },
      "source": [
        "#**Data for part of speech tagging**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yks4wgyVIGKy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "616a4d83-c242-4120-9e89-0ec04df9534e"
      },
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('treebank')\n",
        "nltk.download('universal_tagset')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAT4jvSbIeqG"
      },
      "source": [
        "from nltk.corpus import treebank\n",
        "sentences = treebank.tagged_sents(tagset='universal')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElpHWw76KJFg"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?id=1fJQAmAvb9-17J6gcdvUJHJGyy6Y-hctd)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cukIa5iIqfr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6d748936-38cd-4aeb-af87-c453f177a864"
      },
      "source": [
        "len(sentences)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3914"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_52cHkDhOKBx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "c6b04248-533e-47eb-b2c2-557e6e810ede"
      },
      "source": [
        "tagged_sentence = nltk.corpus.treebank.tagged_sents(tagset='universal')\n",
        "print(\"Number of Tagged Sentences \",len(tagged_sentence))\n",
        "tagged_words=[tup for sent in tagged_sentence for tup in sent]\n",
        "print(\"Total Number of Tagged words\", len(tagged_words))\n",
        "vocab=set([word for word,tag in tagged_words])\n",
        "print(\"Vocabulary of the Corpus\",len(vocab))\n",
        "tags=set([tag for word,tag in tagged_words])\n",
        "print(\"Number of Tags in the Corpus \",len(tags))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Tagged Sentences  3914\n",
            "Total Number of Tagged words 100676\n",
            "Vocabulary of the Corpus 12408\n",
            "Number of Tags in the Corpus  12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmWVc-iFUGtw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f3fd1f69-a1d2-4a0e-c2cf-09643b230acc"
      },
      "source": [
        "print(tags)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'NOUN', 'DET', 'ADV', 'PRON', 'PRT', 'ADP', 'NUM', 'CONJ', 'VERB', 'X', '.', 'ADJ'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4InLSnke5L5"
      },
      "source": [
        "#**Generating Dictionary for our hidden states (Part of speech tags)** -  `transition_probs`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqNSMjN5yamA"
      },
      "source": [
        "`transition_probs` is a dictionary that tells the probability of getting a particular tag as the next POS tag given that which tag had occured previously. \n",
        "\n",
        "Hence using `transition_probs` we get:\n",
        "> `P['next state'|'previous state']`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbDHzRnrf20P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2b912715-cf1d-4687-835f-2616909472ed"
      },
      "source": [
        "import numpy as np\n",
        "states = list(tags)\n",
        "print(states)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['NOUN', 'DET', 'ADV', 'PRON', 'PRT', 'ADP', 'NUM', 'CONJ', 'VERB', 'X', '.', 'ADJ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOkpAbAxW1E4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "8163ff42-7d7e-4a7a-eacb-c296c52bc231"
      },
      "source": [
        "# Generating the martix for calculating transition_probs for the dataset\n",
        "\n",
        "tr_matrix = np.zeros((len(states),len(states)))\n",
        "\n",
        "for sentence in tagged_sentence:\n",
        "  for i in range(len(sentence)):\n",
        "    if i==0: continue\n",
        "    tr_matrix[states.index(sentence[i-1][1])][states.index(sentence[i][1])]+=1\n",
        "\n",
        "print(tr_matrix.astype(int))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[7623  377  490  135 1267 5100  273 1229 4240  837 6926  350]\n",
            " [5569   48  110   31    2   81  193    4  346  398  154 1788]\n",
            " [ 100  218  252   48   45  376  100   22 1093   73  432  411]\n",
            " [ 573   26   93   21   34   62   20   14 1329  254  111  200]\n",
            " [ 796  326   32   58    6   66  183    7 1291   43  138  273]\n",
            " [3173 3194  133  679   14  167  618    8   82  342  392 1050]\n",
            " [1252   11   10    5   96  124  656   48   64  746  414  118]\n",
            " [ 792  270  124  133   11  120   94    1  355   19   80  266]\n",
            " [1497 1822 1110  482  426 1239  310   73 2292 2954  475  884]\n",
            " [ 410  361  170  367 1221  955   18   68 1354  494 1082  112]\n",
            " [1467 1114  412  486   23  565  915  482 1003  229  776  359]\n",
            " [4474   31   30    4   69  497  133  108   77  134  415  425]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68kh49mWgFYP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "d0a0d5f3-e89a-4902-b245-70c86a21d96e"
      },
      "source": [
        "tr_matrix /= np.sum(tr_matrix,keepdims=True,axis=1)\n",
        "print(tr_matrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2.64256248e-01 1.30689500e-02 1.69861684e-02 4.67986272e-03\n",
            "  4.39213783e-02 1.76794814e-01 9.46372240e-03 4.26040836e-02\n",
            "  1.46982355e-01 2.90151489e-02 2.40094291e-01 1.21329774e-02]\n",
            " [6.38353966e-01 5.50206327e-03 1.26088950e-02 3.55341586e-03\n",
            "  2.29252636e-04 9.28473177e-03 2.21228794e-02 4.58505273e-04\n",
            "  3.96607061e-02 4.56212746e-02 1.76524530e-02 2.04951857e-01]\n",
            " [3.15457413e-02 6.87697161e-02 7.94952681e-02 1.51419558e-02\n",
            "  1.41955836e-02 1.18611987e-01 3.15457413e-02 6.94006309e-03\n",
            "  3.44794953e-01 2.30283912e-02 1.36277603e-01 1.29652997e-01]\n",
            " [2.09353307e-01 9.49945195e-03 3.39788089e-02 7.67263427e-03\n",
            "  1.24223602e-02 2.26525393e-02 7.30727073e-03 5.11508951e-03\n",
            "  4.85568140e-01 9.28023383e-02 4.05553526e-02 7.30727073e-02]\n",
            " [2.47281765e-01 1.01273687e-01 9.94097546e-03 1.80180180e-02\n",
            "  1.86393290e-03 2.05032619e-02 5.68499534e-02 2.17458838e-03\n",
            "  4.01056229e-01 1.33581858e-02 4.28704567e-02 8.48089469e-02]\n",
            " [3.22066585e-01 3.24198132e-01 1.34997970e-02 6.89200162e-02\n",
            "  1.42103126e-03 1.69508729e-02 6.27283800e-02 8.12017864e-04\n",
            "  8.32318311e-03 3.47137637e-02 3.97888754e-02 1.06577345e-01]\n",
            " [3.53273138e-01 3.10383747e-03 2.82167043e-03 1.41083521e-03\n",
            "  2.70880361e-02 3.49887133e-02 1.85101580e-01 1.35440181e-02\n",
            "  1.80586907e-02 2.10496614e-01 1.16817156e-01 3.32957111e-02]\n",
            " [3.49668874e-01 1.19205298e-01 5.47461369e-02 5.87196468e-02\n",
            "  4.85651214e-03 5.29801325e-02 4.15011038e-02 4.41501104e-04\n",
            "  1.56732892e-01 8.38852097e-03 3.53200883e-02 1.17439294e-01]\n",
            " [1.10365674e-01 1.34326157e-01 8.18342672e-02 3.55352403e-02\n",
            "  3.14066647e-02 9.13447361e-02 2.28546152e-02 5.38189325e-03\n",
            "  1.68976703e-01 2.17782365e-01 3.50191684e-02 6.51725155e-02]\n",
            " [6.20084694e-02 5.45977011e-02 2.57108288e-02 5.55051422e-02\n",
            "  1.84664247e-01 1.44434362e-01 2.72232305e-03 1.02843315e-02\n",
            "  2.04779189e-01 7.47126437e-02 1.63641863e-01 1.69388990e-02]\n",
            " [1.87332397e-01 1.42255140e-01 5.26114162e-02 6.20610395e-02\n",
            "  2.93704508e-03 7.21491508e-02 1.16843315e-01 6.15502490e-02\n",
            "  1.28080705e-01 2.92427532e-02 9.90933470e-02 4.58434427e-02]\n",
            " [6.99390339e-01 4.84602157e-03 4.68969830e-03 6.25293106e-04\n",
            "  1.07863061e-02 7.76926684e-02 2.07909958e-02 1.68829139e-02\n",
            "  1.20368923e-02 2.09473191e-02 6.48741598e-02 6.64373925e-02]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhCdGwXiiLYd"
      },
      "source": [
        "#Hence we get our transition matrix. Now we need to create the dictionary transition_probs\n",
        "\n",
        "def get_transition_probs(states,tr_matrix):\n",
        "  state_dict = {}\n",
        "  for i,state in enumerate(states):\n",
        "    state_dict[i]=state\n",
        "  transition_probs = {}\n",
        "  for i in range(tr_matrix.shape[0]):\n",
        "    for j in range(tr_matrix.shape[1]):\n",
        "      transition_probs[state_dict[j]+'|'+state_dict[i]] = tr_matrix[i][j]\n",
        "  return transition_probs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leoaZRksGxFi"
      },
      "source": [
        "def get_tr_matrix(states,tagged_sentence):\n",
        "  tr_matrix = np.zeros((len(states),len(states)))\n",
        "  for sentence in tagged_sentence:\n",
        "    for i in range(len(sentence)):\n",
        "      if i==0: continue\n",
        "      tr_matrix[states.index(sentence[i-1][1])][states.index(sentence[i][1])]+=1\n",
        "  tr_matrix /= np.sum(tr_matrix,keepdims=True,axis=1)\n",
        "  return tr_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iIGz9x-x0w2"
      },
      "source": [
        "#**Generating Dictionary for our observable states (words)** - `emission_probs`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94QX9c1Dxi8G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "27871217-5f53-4f33-e9e7-f32a307ed290"
      },
      "source": [
        "vocab = sorted(list(vocab))\n",
        "em_matrix = np.zeros((len(vocab),len(states)))\n",
        "print(em_matrix.shape)\n",
        "\n",
        "for sentence in tagged_sentence:\n",
        "  for word,tag in sentence:\n",
        "    em_matrix[vocab.index(word)][states.index(tag)]+=1\n",
        "\n",
        "print(em_matrix.astype(int))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(12408, 12)\n",
            "[[  0   0   0 ...   0   6   0]\n",
            " [  0   0   0 ...   0  16   0]\n",
            " [  0   0   0 ...   0 718   0]\n",
            " ...\n",
            " [  0   0   0 ...   0   0   0]\n",
            " [  2   0   0 ...   0   0   0]\n",
            " [  0   0   0 ...   0   0   0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuEJOJAXEIxd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "60863dc3-2ad8-4de9-f185-7dd9935b9bef"
      },
      "source": [
        "sum_matrix = np.sum(em_matrix,keepdims=True,axis=0)\n",
        "em_matrix = np.divide(em_matrix, sum_matrix, out=np.zeros_like(em_matrix), where=sum_matrix!=0)\n",
        "print(em_matrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "  5.12163892e-04 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "  1.36577038e-03 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "  6.12889458e-02 0.00000000e+00]\n",
            " ...\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [6.92832646e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEkQZx387z2X"
      },
      "source": [
        "#Hence we get our emission matrix. Now we need to create the dictionary transition_probs\n",
        "def get_emission_probs(states,vocab,em_matrix):\n",
        "  state_dict = {}\n",
        "  for i,state in enumerate(states):\n",
        "    state_dict[i]=state\n",
        "  emission_probs = {}\n",
        "  for i in range(em_matrix.shape[0]):\n",
        "    for j in range(em_matrix.shape[1]):\n",
        "      emission_probs[vocab[i]+'|'+state_dict[j]] = em_matrix[i][j]\n",
        "  return emission_probs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zo9Ewk4F4no"
      },
      "source": [
        "def get_em_matrix(states,vocab,tagged_sentence):\n",
        "  vocab = sorted(list(vocab))\n",
        "  em_matrix = np.zeros((len(vocab),len(states)))\n",
        "  for sentence in tagged_sentence:\n",
        "    for word,tag in sentence:\n",
        "      em_matrix[vocab.index(word)][states.index(tag)]+=1\n",
        "  sum_matrix = np.sum(em_matrix,keepdims=True,axis=0)\n",
        "  em_matrix = np.divide(em_matrix, sum_matrix, out=np.zeros_like(em_matrix), where=sum_matrix!=0)\n",
        "  return em_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1c7JQnBEwEv"
      },
      "source": [
        "def get_probs(states,vocab,tagged_sentence):\n",
        "  tr_matrix = get_tr_matrix(states,tagged_sentence)\n",
        "  em_matrix = get_em_matrix(states,vocab,tagged_sentence)\n",
        "  transition_probs = get_transition_probs(states,tr_matrix)\n",
        "  emission_probs = get_emission_probs(states,vocab,em_matrix)\n",
        "  return transition_probs,emission_probs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkcTmfogIiaU"
      },
      "source": [
        "def get_initial_probs(states,tagged_sentence):\n",
        "  initial_list = [0]*len(states)\n",
        "  for sent in tagged_sentence:\n",
        "    tag = sent[0][1]\n",
        "    initial_list[states.index(tag)]+=1\n",
        "  initial_list = np.asarray(initial_list)\n",
        "  initial_list = initial_list/np.sum(initial_list,keepdims=True)\n",
        "  initial_probs = {}\n",
        "  for i,state in enumerate(states):\n",
        "    initial_probs[state] = initial_list[i]\n",
        "  return initial_probs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBtB4_OaNYIj"
      },
      "source": [
        "def get_observation(sent):\n",
        "  ob = []\n",
        "  ob_tags = []\n",
        "  for word,tag in sent:\n",
        "    ob.append(word)\n",
        "    ob_tags.append(tag)\n",
        "  return ob,ob_tags"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B53o4VzoICNj"
      },
      "source": [
        "initial_probs = get_initial_probs(states,tagged_sentence)\n",
        "\n",
        "probs = get_probs(states,vocab,tagged_sentence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-96g2ohbGO-"
      },
      "source": [
        "# **Testing our Hidden Markov Model on the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASkd0bNQKvXB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "6c14a590-4dca-484c-8bce-f310f6290d2e"
      },
      "source": [
        "import random\n",
        "ob = random.choice(tagged_sentence)\n",
        "obs,ob_tags = get_observation(ob)\n",
        "\n",
        "cache,l = viterbi(states,probs,initial_probs,obs)\n",
        "print(\"Finding the best hidden sequence from the path generated by viterbi algorithm...\")\n",
        "print()\n",
        "best_seq,_ = viterbi_backward(states,cache,l)\n",
        "print(\"TAGS ACHIEVED USING HIDDEN MARKOV MODEL-\",best_seq,sep=\"\\n\")\n",
        "print()\n",
        "print(\"ACTUAL TAGS-\",ob_tags,sep=\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finding the best hidden sequence from the path generated by viterbi algorithm...\n",
            "\n",
            "TAGS ACHIEVED USING HIDDEN MARKOV MODEL-\n",
            "['CONJ', 'NOUN', 'ADP', 'NOUN', 'NOUN', 'VERB', 'X', 'PRON', 'VERB', 'ADJ', 'X', 'PRT', 'VERB', '.', 'ADP', 'ADV', 'ADP', 'NOUN', '.', 'ADV', 'ADP', 'NOUN', 'CONJ', 'NOUN', '.']\n",
            "\n",
            "ACTUAL TAGS-\n",
            "['CONJ', 'NOUN', 'ADP', 'NOUN', 'NOUN', 'VERB', 'X', 'PRON', 'VERB', 'ADJ', 'X', 'PRT', 'VERB', '.', 'ADJ', 'ADV', 'ADP', 'NOUN', '.', 'ADV', 'ADP', 'NOUN', 'CONJ', 'NOUN', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5MpwUcHZ-am"
      },
      "source": [
        "#**Further improvements**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uH9aSnxmc4oC"
      },
      "source": [
        "If we carefully examine the dataset and our code, we would realise that we have actually overfitted the data. Hence we are getting extremely accurate results without any preprocessing. For example, our `vocab` that we generate from the dataset has a huge count of irrelevant items. The `vocab` explicitly includes numbers and patterns like ' 12 ' , ' 3762 ' , ' \\* U \\* ' , ' \\* v - 10 ' and even proper nouns like ' David ' , ' Sam ' etc. We must pre process our dataset so that our model can generalise even better. Using Hidden Markov Model demands for certain preprocessing of the data that has not been considered in the above notebook, and hence can be worked upon for further improvements. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTZxiAjFjFbM"
      },
      "source": [
        "#**Conclusion**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aiv-qWxjBxz"
      },
      "source": [
        "\n",
        "1. Hidden Markov Model has been built using Viterbi Algorithm \n",
        "\n",
        "2. Part of speech tagging has been implemented using HMM model.\n",
        "\n",
        "3. We have used the `tree-bank` dataset from `nltk.corpus` to test our model."
      ]
    }
  ]
}